{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViTの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT is implemented\n"
     ]
    }
   ],
   "source": [
    "#### 1. Modelの読み込み\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from vit import ViT\n",
    "import matplotlib.pyplot as plt\n",
    "batch_size = 2\n",
    "channel = 3 \n",
    "img_size= 256\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "model = ViT(in_channels = channel,\n",
    "            image_size = img_size,\n",
    "            num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is  torch.Size([2, 3, 32, 32])\n",
      "Output shape is  torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(batch_size, channel, img_size, img_size)\n",
    "print(\"Input shape is \",x.shape)\n",
    "pred = model(x)\n",
    "print(\"Output shape is \",pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6904,  0.1335,  0.4351,  0.2070,  0.3900,  0.3058, -0.4890,  0.4632,\n",
       "         -0.2290, -0.1032],\n",
       "        [-0.1669,  0.0364,  0.4717,  0.1971,  0.3912,  0.6214, -0.1685,  0.3711,\n",
       "         -0.7593, -0.0703]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0].permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 384, 2, 2]         295,296\n",
      "           Dropout-2               [-1, 5, 384]               0\n",
      "   ViT_input_Layer-3               [-1, 5, 384]               0\n",
      "         LayerNorm-4               [-1, 5, 384]             768\n",
      "            Linear-5               [-1, 5, 384]         147,456\n",
      "            Linear-6               [-1, 5, 384]         147,456\n",
      "            Linear-7               [-1, 5, 384]         147,456\n",
      "            Linear-8               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-9               [-1, 5, 384]               0\n",
      "        LayerNorm-10               [-1, 5, 384]             768\n",
      "           Linear-11              [-1, 5, 1536]         591,360\n",
      "             GELU-12              [-1, 5, 1536]               0\n",
      "          Dropout-13              [-1, 5, 1536]               0\n",
      "           Linear-14               [-1, 5, 384]         590,208\n",
      "          Dropout-15               [-1, 5, 384]               0\n",
      "    Encoder_Block-16               [-1, 5, 384]               0\n",
      "        LayerNorm-17               [-1, 5, 384]             768\n",
      "           Linear-18               [-1, 5, 384]         147,456\n",
      "           Linear-19               [-1, 5, 384]         147,456\n",
      "           Linear-20               [-1, 5, 384]         147,456\n",
      "           Linear-21               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-22               [-1, 5, 384]               0\n",
      "        LayerNorm-23               [-1, 5, 384]             768\n",
      "           Linear-24              [-1, 5, 1536]         591,360\n",
      "             GELU-25              [-1, 5, 1536]               0\n",
      "          Dropout-26              [-1, 5, 1536]               0\n",
      "           Linear-27               [-1, 5, 384]         590,208\n",
      "          Dropout-28               [-1, 5, 384]               0\n",
      "    Encoder_Block-29               [-1, 5, 384]               0\n",
      "        LayerNorm-30               [-1, 5, 384]             768\n",
      "           Linear-31               [-1, 5, 384]         147,456\n",
      "           Linear-32               [-1, 5, 384]         147,456\n",
      "           Linear-33               [-1, 5, 384]         147,456\n",
      "           Linear-34               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-35               [-1, 5, 384]               0\n",
      "        LayerNorm-36               [-1, 5, 384]             768\n",
      "           Linear-37              [-1, 5, 1536]         591,360\n",
      "             GELU-38              [-1, 5, 1536]               0\n",
      "          Dropout-39              [-1, 5, 1536]               0\n",
      "           Linear-40               [-1, 5, 384]         590,208\n",
      "          Dropout-41               [-1, 5, 384]               0\n",
      "    Encoder_Block-42               [-1, 5, 384]               0\n",
      "        LayerNorm-43               [-1, 5, 384]             768\n",
      "           Linear-44               [-1, 5, 384]         147,456\n",
      "           Linear-45               [-1, 5, 384]         147,456\n",
      "           Linear-46               [-1, 5, 384]         147,456\n",
      "           Linear-47               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-48               [-1, 5, 384]               0\n",
      "        LayerNorm-49               [-1, 5, 384]             768\n",
      "           Linear-50              [-1, 5, 1536]         591,360\n",
      "             GELU-51              [-1, 5, 1536]               0\n",
      "          Dropout-52              [-1, 5, 1536]               0\n",
      "           Linear-53               [-1, 5, 384]         590,208\n",
      "          Dropout-54               [-1, 5, 384]               0\n",
      "    Encoder_Block-55               [-1, 5, 384]               0\n",
      "        LayerNorm-56               [-1, 5, 384]             768\n",
      "           Linear-57               [-1, 5, 384]         147,456\n",
      "           Linear-58               [-1, 5, 384]         147,456\n",
      "           Linear-59               [-1, 5, 384]         147,456\n",
      "           Linear-60               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-61               [-1, 5, 384]               0\n",
      "        LayerNorm-62               [-1, 5, 384]             768\n",
      "           Linear-63              [-1, 5, 1536]         591,360\n",
      "             GELU-64              [-1, 5, 1536]               0\n",
      "          Dropout-65              [-1, 5, 1536]               0\n",
      "           Linear-66               [-1, 5, 384]         590,208\n",
      "          Dropout-67               [-1, 5, 384]               0\n",
      "    Encoder_Block-68               [-1, 5, 384]               0\n",
      "        LayerNorm-69               [-1, 5, 384]             768\n",
      "           Linear-70               [-1, 5, 384]         147,456\n",
      "           Linear-71               [-1, 5, 384]         147,456\n",
      "           Linear-72               [-1, 5, 384]         147,456\n",
      "           Linear-73               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-74               [-1, 5, 384]               0\n",
      "        LayerNorm-75               [-1, 5, 384]             768\n",
      "           Linear-76              [-1, 5, 1536]         591,360\n",
      "             GELU-77              [-1, 5, 1536]               0\n",
      "          Dropout-78              [-1, 5, 1536]               0\n",
      "           Linear-79               [-1, 5, 384]         590,208\n",
      "          Dropout-80               [-1, 5, 384]               0\n",
      "    Encoder_Block-81               [-1, 5, 384]               0\n",
      "        LayerNorm-82               [-1, 5, 384]             768\n",
      "           Linear-83               [-1, 5, 384]         147,456\n",
      "           Linear-84               [-1, 5, 384]         147,456\n",
      "           Linear-85               [-1, 5, 384]         147,456\n",
      "           Linear-86               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-87               [-1, 5, 384]               0\n",
      "        LayerNorm-88               [-1, 5, 384]             768\n",
      "           Linear-89              [-1, 5, 1536]         591,360\n",
      "             GELU-90              [-1, 5, 1536]               0\n",
      "          Dropout-91              [-1, 5, 1536]               0\n",
      "           Linear-92               [-1, 5, 384]         590,208\n",
      "          Dropout-93               [-1, 5, 384]               0\n",
      "    Encoder_Block-94               [-1, 5, 384]               0\n",
      "        LayerNorm-95               [-1, 5, 384]             768\n",
      "           Linear-96               [-1, 5, 384]         147,456\n",
      "           Linear-97               [-1, 5, 384]         147,456\n",
      "           Linear-98               [-1, 5, 384]         147,456\n",
      "           Linear-99               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-100               [-1, 5, 384]               0\n",
      "       LayerNorm-101               [-1, 5, 384]             768\n",
      "          Linear-102              [-1, 5, 1536]         591,360\n",
      "            GELU-103              [-1, 5, 1536]               0\n",
      "         Dropout-104              [-1, 5, 1536]               0\n",
      "          Linear-105               [-1, 5, 384]         590,208\n",
      "         Dropout-106               [-1, 5, 384]               0\n",
      "   Encoder_Block-107               [-1, 5, 384]               0\n",
      "       LayerNorm-108               [-1, 5, 384]             768\n",
      "          Linear-109               [-1, 5, 384]         147,456\n",
      "          Linear-110               [-1, 5, 384]         147,456\n",
      "          Linear-111               [-1, 5, 384]         147,456\n",
      "          Linear-112               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-113               [-1, 5, 384]               0\n",
      "       LayerNorm-114               [-1, 5, 384]             768\n",
      "          Linear-115              [-1, 5, 1536]         591,360\n",
      "            GELU-116              [-1, 5, 1536]               0\n",
      "         Dropout-117              [-1, 5, 1536]               0\n",
      "          Linear-118               [-1, 5, 384]         590,208\n",
      "         Dropout-119               [-1, 5, 384]               0\n",
      "   Encoder_Block-120               [-1, 5, 384]               0\n",
      "       LayerNorm-121               [-1, 5, 384]             768\n",
      "          Linear-122               [-1, 5, 384]         147,456\n",
      "          Linear-123               [-1, 5, 384]         147,456\n",
      "          Linear-124               [-1, 5, 384]         147,456\n",
      "          Linear-125               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-126               [-1, 5, 384]               0\n",
      "       LayerNorm-127               [-1, 5, 384]             768\n",
      "          Linear-128              [-1, 5, 1536]         591,360\n",
      "            GELU-129              [-1, 5, 1536]               0\n",
      "         Dropout-130              [-1, 5, 1536]               0\n",
      "          Linear-131               [-1, 5, 384]         590,208\n",
      "         Dropout-132               [-1, 5, 384]               0\n",
      "   Encoder_Block-133               [-1, 5, 384]               0\n",
      "       LayerNorm-134               [-1, 5, 384]             768\n",
      "          Linear-135               [-1, 5, 384]         147,456\n",
      "          Linear-136               [-1, 5, 384]         147,456\n",
      "          Linear-137               [-1, 5, 384]         147,456\n",
      "          Linear-138               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-139               [-1, 5, 384]               0\n",
      "       LayerNorm-140               [-1, 5, 384]             768\n",
      "          Linear-141              [-1, 5, 1536]         591,360\n",
      "            GELU-142              [-1, 5, 1536]               0\n",
      "         Dropout-143              [-1, 5, 1536]               0\n",
      "          Linear-144               [-1, 5, 384]         590,208\n",
      "         Dropout-145               [-1, 5, 384]               0\n",
      "   Encoder_Block-146               [-1, 5, 384]               0\n",
      "       LayerNorm-147               [-1, 5, 384]             768\n",
      "          Linear-148               [-1, 5, 384]         147,456\n",
      "          Linear-149               [-1, 5, 384]         147,456\n",
      "          Linear-150               [-1, 5, 384]         147,456\n",
      "          Linear-151               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-152               [-1, 5, 384]               0\n",
      "       LayerNorm-153               [-1, 5, 384]             768\n",
      "          Linear-154              [-1, 5, 1536]         591,360\n",
      "            GELU-155              [-1, 5, 1536]               0\n",
      "         Dropout-156              [-1, 5, 1536]               0\n",
      "          Linear-157               [-1, 5, 384]         590,208\n",
      "         Dropout-158               [-1, 5, 384]               0\n",
      "   Encoder_Block-159               [-1, 5, 384]               0\n",
      "       LayerNorm-160                  [-1, 384]             768\n",
      "          Linear-161                   [-1, 10]           3,850\n",
      "================================================================\n",
      "Total params: 21,579,658\n",
      "Trainable params: 21,579,658\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.91\n",
      "Params size (MB): 82.32\n",
      "Estimated Total Size (MB): 86.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "# Assuming your model is already defined as 'model' and is compatible with the input dimensions\n",
    "summary(model, input_size=(channel, img_size, img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  21581962\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of parameters in the model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(\"Total number of parameters: \", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
