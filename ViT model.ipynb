{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViTの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1. import the necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from vit import ViT\n",
    "import matplotlib.pyplot as plt\n",
    "from train import train\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Check the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Dataloader - Batch size: 32, Image size: 32x32\n",
      "Eval Dataloader - Batch size: 32, Image size: 32x32\n",
      "Test Dataloader - Batch size: 32, Image size: 32x32\n",
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_dataloader\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloader()\n",
    "# Check the image size and batch size from the first batch of each dataloader\n",
    "for name, dataloader in zip(['Train', 'Eval', 'Test'], [train_dataloader, val_dataloader, test_dataloader]):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    ## image.shape = (batch_size, channel, img_size, img_size)\n",
    "    print(f\"{name} Dataloader - Batch size: {images.shape[0]}, Image size: {images.shape[2]}x{images.shape[3]}\")\n",
    "print(\"Classes:\",train_dataloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT is implemented\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 384, 2, 2]         295,296\n",
      "           Dropout-2               [-1, 5, 384]               0\n",
      "   ViT_input_Layer-3               [-1, 5, 384]               0\n",
      "         LayerNorm-4               [-1, 5, 384]             768\n",
      "            Linear-5               [-1, 5, 384]         147,456\n",
      "            Linear-6               [-1, 5, 384]         147,456\n",
      "            Linear-7               [-1, 5, 384]         147,456\n",
      "            Linear-8               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-9               [-1, 5, 384]               0\n",
      "        LayerNorm-10               [-1, 5, 384]             768\n",
      "           Linear-11              [-1, 5, 1536]         591,360\n",
      "             GELU-12              [-1, 5, 1536]               0\n",
      "          Dropout-13              [-1, 5, 1536]               0\n",
      "           Linear-14               [-1, 5, 384]         590,208\n",
      "          Dropout-15               [-1, 5, 384]               0\n",
      "    Encoder_Block-16               [-1, 5, 384]               0\n",
      "        LayerNorm-17               [-1, 5, 384]             768\n",
      "           Linear-18               [-1, 5, 384]         147,456\n",
      "           Linear-19               [-1, 5, 384]         147,456\n",
      "           Linear-20               [-1, 5, 384]         147,456\n",
      "           Linear-21               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-22               [-1, 5, 384]               0\n",
      "        LayerNorm-23               [-1, 5, 384]             768\n",
      "           Linear-24              [-1, 5, 1536]         591,360\n",
      "             GELU-25              [-1, 5, 1536]               0\n",
      "          Dropout-26              [-1, 5, 1536]               0\n",
      "           Linear-27               [-1, 5, 384]         590,208\n",
      "          Dropout-28               [-1, 5, 384]               0\n",
      "    Encoder_Block-29               [-1, 5, 384]               0\n",
      "        LayerNorm-30               [-1, 5, 384]             768\n",
      "           Linear-31               [-1, 5, 384]         147,456\n",
      "           Linear-32               [-1, 5, 384]         147,456\n",
      "           Linear-33               [-1, 5, 384]         147,456\n",
      "           Linear-34               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-35               [-1, 5, 384]               0\n",
      "        LayerNorm-36               [-1, 5, 384]             768\n",
      "           Linear-37              [-1, 5, 1536]         591,360\n",
      "             GELU-38              [-1, 5, 1536]               0\n",
      "          Dropout-39              [-1, 5, 1536]               0\n",
      "           Linear-40               [-1, 5, 384]         590,208\n",
      "          Dropout-41               [-1, 5, 384]               0\n",
      "    Encoder_Block-42               [-1, 5, 384]               0\n",
      "        LayerNorm-43               [-1, 5, 384]             768\n",
      "           Linear-44               [-1, 5, 384]         147,456\n",
      "           Linear-45               [-1, 5, 384]         147,456\n",
      "           Linear-46               [-1, 5, 384]         147,456\n",
      "           Linear-47               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-48               [-1, 5, 384]               0\n",
      "        LayerNorm-49               [-1, 5, 384]             768\n",
      "           Linear-50              [-1, 5, 1536]         591,360\n",
      "             GELU-51              [-1, 5, 1536]               0\n",
      "          Dropout-52              [-1, 5, 1536]               0\n",
      "           Linear-53               [-1, 5, 384]         590,208\n",
      "          Dropout-54               [-1, 5, 384]               0\n",
      "    Encoder_Block-55               [-1, 5, 384]               0\n",
      "        LayerNorm-56               [-1, 5, 384]             768\n",
      "           Linear-57               [-1, 5, 384]         147,456\n",
      "           Linear-58               [-1, 5, 384]         147,456\n",
      "           Linear-59               [-1, 5, 384]         147,456\n",
      "           Linear-60               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-61               [-1, 5, 384]               0\n",
      "        LayerNorm-62               [-1, 5, 384]             768\n",
      "           Linear-63              [-1, 5, 1536]         591,360\n",
      "             GELU-64              [-1, 5, 1536]               0\n",
      "          Dropout-65              [-1, 5, 1536]               0\n",
      "           Linear-66               [-1, 5, 384]         590,208\n",
      "          Dropout-67               [-1, 5, 384]               0\n",
      "    Encoder_Block-68               [-1, 5, 384]               0\n",
      "        LayerNorm-69               [-1, 5, 384]             768\n",
      "           Linear-70               [-1, 5, 384]         147,456\n",
      "           Linear-71               [-1, 5, 384]         147,456\n",
      "           Linear-72               [-1, 5, 384]         147,456\n",
      "           Linear-73               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-74               [-1, 5, 384]               0\n",
      "        LayerNorm-75               [-1, 5, 384]             768\n",
      "           Linear-76              [-1, 5, 1536]         591,360\n",
      "             GELU-77              [-1, 5, 1536]               0\n",
      "          Dropout-78              [-1, 5, 1536]               0\n",
      "           Linear-79               [-1, 5, 384]         590,208\n",
      "          Dropout-80               [-1, 5, 384]               0\n",
      "    Encoder_Block-81               [-1, 5, 384]               0\n",
      "        LayerNorm-82               [-1, 5, 384]             768\n",
      "           Linear-83               [-1, 5, 384]         147,456\n",
      "           Linear-84               [-1, 5, 384]         147,456\n",
      "           Linear-85               [-1, 5, 384]         147,456\n",
      "           Linear-86               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-87               [-1, 5, 384]               0\n",
      "        LayerNorm-88               [-1, 5, 384]             768\n",
      "           Linear-89              [-1, 5, 1536]         591,360\n",
      "             GELU-90              [-1, 5, 1536]               0\n",
      "          Dropout-91              [-1, 5, 1536]               0\n",
      "           Linear-92               [-1, 5, 384]         590,208\n",
      "          Dropout-93               [-1, 5, 384]               0\n",
      "    Encoder_Block-94               [-1, 5, 384]               0\n",
      "        LayerNorm-95               [-1, 5, 384]             768\n",
      "           Linear-96               [-1, 5, 384]         147,456\n",
      "           Linear-97               [-1, 5, 384]         147,456\n",
      "           Linear-98               [-1, 5, 384]         147,456\n",
      "           Linear-99               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-100               [-1, 5, 384]               0\n",
      "       LayerNorm-101               [-1, 5, 384]             768\n",
      "          Linear-102              [-1, 5, 1536]         591,360\n",
      "            GELU-103              [-1, 5, 1536]               0\n",
      "         Dropout-104              [-1, 5, 1536]               0\n",
      "          Linear-105               [-1, 5, 384]         590,208\n",
      "         Dropout-106               [-1, 5, 384]               0\n",
      "   Encoder_Block-107               [-1, 5, 384]               0\n",
      "       LayerNorm-108               [-1, 5, 384]             768\n",
      "          Linear-109               [-1, 5, 384]         147,456\n",
      "          Linear-110               [-1, 5, 384]         147,456\n",
      "          Linear-111               [-1, 5, 384]         147,456\n",
      "          Linear-112               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-113               [-1, 5, 384]               0\n",
      "       LayerNorm-114               [-1, 5, 384]             768\n",
      "          Linear-115              [-1, 5, 1536]         591,360\n",
      "            GELU-116              [-1, 5, 1536]               0\n",
      "         Dropout-117              [-1, 5, 1536]               0\n",
      "          Linear-118               [-1, 5, 384]         590,208\n",
      "         Dropout-119               [-1, 5, 384]               0\n",
      "   Encoder_Block-120               [-1, 5, 384]               0\n",
      "       LayerNorm-121               [-1, 5, 384]             768\n",
      "          Linear-122               [-1, 5, 384]         147,456\n",
      "          Linear-123               [-1, 5, 384]         147,456\n",
      "          Linear-124               [-1, 5, 384]         147,456\n",
      "          Linear-125               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-126               [-1, 5, 384]               0\n",
      "       LayerNorm-127               [-1, 5, 384]             768\n",
      "          Linear-128              [-1, 5, 1536]         591,360\n",
      "            GELU-129              [-1, 5, 1536]               0\n",
      "         Dropout-130              [-1, 5, 1536]               0\n",
      "          Linear-131               [-1, 5, 384]         590,208\n",
      "         Dropout-132               [-1, 5, 384]               0\n",
      "   Encoder_Block-133               [-1, 5, 384]               0\n",
      "       LayerNorm-134               [-1, 5, 384]             768\n",
      "          Linear-135               [-1, 5, 384]         147,456\n",
      "          Linear-136               [-1, 5, 384]         147,456\n",
      "          Linear-137               [-1, 5, 384]         147,456\n",
      "          Linear-138               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-139               [-1, 5, 384]               0\n",
      "       LayerNorm-140               [-1, 5, 384]             768\n",
      "          Linear-141              [-1, 5, 1536]         591,360\n",
      "            GELU-142              [-1, 5, 1536]               0\n",
      "         Dropout-143              [-1, 5, 1536]               0\n",
      "          Linear-144               [-1, 5, 384]         590,208\n",
      "         Dropout-145               [-1, 5, 384]               0\n",
      "   Encoder_Block-146               [-1, 5, 384]               0\n",
      "       LayerNorm-147               [-1, 5, 384]             768\n",
      "          Linear-148               [-1, 5, 384]         147,456\n",
      "          Linear-149               [-1, 5, 384]         147,456\n",
      "          Linear-150               [-1, 5, 384]         147,456\n",
      "          Linear-151               [-1, 5, 384]         147,840\n",
      "Self_Attention_Layer-152               [-1, 5, 384]               0\n",
      "       LayerNorm-153               [-1, 5, 384]             768\n",
      "          Linear-154              [-1, 5, 1536]         591,360\n",
      "            GELU-155              [-1, 5, 1536]               0\n",
      "         Dropout-156              [-1, 5, 1536]               0\n",
      "          Linear-157               [-1, 5, 384]         590,208\n",
      "         Dropout-158               [-1, 5, 384]               0\n",
      "   Encoder_Block-159               [-1, 5, 384]               0\n",
      "       LayerNorm-160                  [-1, 384]             768\n",
      "          Linear-161                   [-1, 10]           3,850\n",
      "================================================================\n",
      "Total params: 21,579,658\n",
      "Trainable params: 21,579,658\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.91\n",
      "Params size (MB): 82.32\n",
      "Estimated Total Size (MB): 86.24\n",
      "----------------------------------------------------------------\n",
      "Input shape is  torch.Size([32, 3, 32, 32])\n",
      "Output shape is  torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "batch_size = images.shape[0]\n",
    "channel = images.shape[1]\n",
    "img_size = images.shape[2]\n",
    "num_classes = len(train_dataloader.dataset.classes) ## Using CIFAR10\n",
    "\n",
    "model = ViT(in_channels = channel,\n",
    "            image_size = img_size,\n",
    "            num_classes = num_classes)\n",
    "summary(model, input_size=(channel, img_size, img_size))\n",
    "x = torch.randn(batch_size, channel, img_size, img_size)\n",
    "print(\"Input shape is \",x.shape)\n",
    "pred = model(x)\n",
    "print(\"Output shape is \",pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "train(model, train_dataloader, val_dataloader, test_dataloader, num_epochs, optimizer, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
